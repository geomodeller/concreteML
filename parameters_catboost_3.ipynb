{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7caf4262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from catboost import CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757a53df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 17:38:06,098] A new study created in memory with name: no-name-3c56ac52-3dc1-4432-981c-00408f258b16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 17:38:09,021] Trial 0 finished with value: 0.9497034818115826 and parameters: {'iterations': 746, 'learning_rate': 0.1257236240236609, 'depth': 8}. Best is trial 0 with value: 0.9497034818115826.\n",
      "[I 2025-07-30 17:38:10,030] Trial 1 finished with value: 0.9461303034238112 and parameters: {'iterations': 602, 'learning_rate': 0.13058574815609694, 'depth': 6}. Best is trial 0 with value: 0.9497034818115826.\n",
      "[I 2025-07-30 17:38:13,499] Trial 2 finished with value: 0.9536688557912703 and parameters: {'iterations': 967, 'learning_rate': 0.08183881227618986, 'depth': 8}. Best is trial 2 with value: 0.9536688557912703.\n",
      "[I 2025-07-30 17:38:16,833] Trial 3 finished with value: 0.9423960767681697 and parameters: {'iterations': 266, 'learning_rate': 0.18593074206887825, 'depth': 10}. Best is trial 2 with value: 0.9536688557912703.\n",
      "[I 2025-07-30 17:38:17,065] Trial 4 finished with value: 0.8986250203770284 and parameters: {'iterations': 208, 'learning_rate': 0.0979872744761593, 'depth': 4}. Best is trial 2 with value: 0.9536688557912703.\n",
      "[I 2025-07-30 17:38:17,536] Trial 5 finished with value: 0.902029556525124 and parameters: {'iterations': 515, 'learning_rate': 0.04003068138835939, 'depth': 4}. Best is trial 2 with value: 0.9536688557912703.\n",
      "[I 2025-07-30 17:38:17,953] Trial 6 finished with value: 0.9493122948121507 and parameters: {'iterations': 337, 'learning_rate': 0.20494877136306672, 'depth': 5}. Best is trial 2 with value: 0.9536688557912703.\n",
      "[I 2025-07-30 17:38:21,750] Trial 7 finished with value: 0.9530237755153832 and parameters: {'iterations': 620, 'learning_rate': 0.10504257981357319, 'depth': 9}. Best is trial 2 with value: 0.9536688557912703.\n",
      "[I 2025-07-30 17:38:22,017] Trial 8 finished with value: 0.9264032191583778 and parameters: {'iterations': 265, 'learning_rate': 0.20210000962857036, 'depth': 4}. Best is trial 2 with value: 0.9536688557912703.\n",
      "[I 2025-07-30 17:38:24,017] Trial 9 finished with value: 0.9496576356431117 and parameters: {'iterations': 330, 'learning_rate': 0.29359331240306197, 'depth': 9}. Best is trial 2 with value: 0.9536688557912703.\n",
      "[I 2025-07-30 17:38:26,283] Trial 10 finished with value: 0.9220909898059315 and parameters: {'iterations': 977, 'learning_rate': 0.016701048404868968, 'depth': 7}. Best is trial 2 with value: 0.9536688557912703.\n",
      "[I 2025-07-30 17:38:29,433] Trial 11 finished with value: 0.9525117501007032 and parameters: {'iterations': 872, 'learning_rate': 0.07309638002721018, 'depth': 8}. Best is trial 2 with value: 0.9536688557912703.\n",
      "[I 2025-07-30 17:38:38,301] Trial 12 finished with value: 0.945861961411878 and parameters: {'iterations': 702, 'learning_rate': 0.07247145238131245, 'depth': 10}. Best is trial 2 with value: 0.9536688557912703.\n",
      "[I 2025-07-30 17:38:40,181] Trial 13 finished with value: 0.9491043729341868 and parameters: {'iterations': 496, 'learning_rate': 0.16847898957792118, 'depth': 8}. Best is trial 2 with value: 0.9536688557912703.\n",
      "[I 2025-07-30 17:38:46,131] Trial 14 finished with value: 0.9552903732086933 and parameters: {'iterations': 990, 'learning_rate': 0.10402230857451009, 'depth': 9}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:38:48,351] Trial 15 finished with value: 0.945995357737416 and parameters: {'iterations': 958, 'learning_rate': 0.04852799107413588, 'depth': 7}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:38:53,454] Trial 16 finished with value: 0.9485910190359026 and parameters: {'iterations': 843, 'learning_rate': 0.24649670454476236, 'depth': 9}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:38:54,803] Trial 17 finished with value: 0.9516031281528627 and parameters: {'iterations': 842, 'learning_rate': 0.1358650577219955, 'depth': 6}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:39:07,298] Trial 18 finished with value: 0.9454296339033366 and parameters: {'iterations': 997, 'learning_rate': 0.08568720468587332, 'depth': 10}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:39:10,169] Trial 19 finished with value: 0.9190799134923011 and parameters: {'iterations': 765, 'learning_rate': 0.016390216494773374, 'depth': 8}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:39:10,294] Trial 20 finished with value: 0.8752575817370812 and parameters: {'iterations': 113, 'learning_rate': 0.16047224019364836, 'depth': 3}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:39:14,242] Trial 21 finished with value: 0.9516713506935546 and parameters: {'iterations': 652, 'learning_rate': 0.10666883037483997, 'depth': 9}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:39:19,698] Trial 22 finished with value: 0.9488504646615888 and parameters: {'iterations': 892, 'learning_rate': 0.05163097000655759, 'depth': 9}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:39:20,784] Trial 23 finished with value: 0.9479419685506656 and parameters: {'iterations': 447, 'learning_rate': 0.10921043831657164, 'depth': 7}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:39:25,738] Trial 24 finished with value: 0.954040569295807 and parameters: {'iterations': 786, 'learning_rate': 0.14607986058099703, 'depth': 9}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:39:29,241] Trial 25 finished with value: 0.9500142103439464 and parameters: {'iterations': 926, 'learning_rate': 0.14594552012364478, 'depth': 8}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:39:39,050] Trial 26 finished with value: 0.9415079669097799 and parameters: {'iterations': 764, 'learning_rate': 0.23454276992758805, 'depth': 10}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:39:44,177] Trial 27 finished with value: 0.9525390010850825 and parameters: {'iterations': 825, 'learning_rate': 0.07576762479014539, 'depth': 9}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:39:46,312] Trial 28 finished with value: 0.9535131977314811 and parameters: {'iterations': 915, 'learning_rate': 0.12304982224502536, 'depth': 7}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:39:49,010] Trial 29 finished with value: 0.9492652558776189 and parameters: {'iterations': 721, 'learning_rate': 0.17708902911429947, 'depth': 8}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:39:59,248] Trial 30 finished with value: 0.946275296730746 and parameters: {'iterations': 813, 'learning_rate': 0.1508977483431049, 'depth': 10}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:40:01,350] Trial 31 finished with value: 0.9519194715910326 and parameters: {'iterations': 918, 'learning_rate': 0.12259097464448947, 'depth': 7}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:40:02,815] Trial 32 finished with value: 0.9494929321993266 and parameters: {'iterations': 936, 'learning_rate': 0.12490114845622835, 'depth': 6}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:40:06,348] Trial 33 finished with value: 0.9545887798924938 and parameters: {'iterations': 981, 'learning_rate': 0.0883506389820225, 'depth': 8}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:40:09,949] Trial 34 finished with value: 0.9493889220416489 and parameters: {'iterations': 988, 'learning_rate': 0.05902121377778393, 'depth': 8}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:40:14,783] Trial 35 finished with value: 0.9507712716415214 and parameters: {'iterations': 806, 'learning_rate': 0.09200587744702024, 'depth': 9}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:40:18,435] Trial 36 finished with value: 0.9473129383296389 and parameters: {'iterations': 1000, 'learning_rate': 0.034226677204064394, 'depth': 8}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:40:23,699] Trial 37 finished with value: 0.9509504552707048 and parameters: {'iterations': 876, 'learning_rate': 0.08782057192209103, 'depth': 9}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:40:32,315] Trial 38 finished with value: 0.9435054581807671 and parameters: {'iterations': 692, 'learning_rate': 0.1359478692265459, 'depth': 10}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:40:35,732] Trial 39 finished with value: 0.9513378106400262 and parameters: {'iterations': 947, 'learning_rate': 0.19107077134368403, 'depth': 8}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:40:39,116] Trial 40 finished with value: 0.9527789570059756 and parameters: {'iterations': 559, 'learning_rate': 0.11108347468190605, 'depth': 9}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:40:41,272] Trial 41 finished with value: 0.9512552193650353 and parameters: {'iterations': 894, 'learning_rate': 0.11268647025594902, 'depth': 7}. Best is trial 14 with value: 0.9552903732086933.\n",
      "[I 2025-07-30 17:40:42,378] Trial 42 finished with value: 0.955885524229918 and parameters: {'iterations': 931, 'learning_rate': 0.1252659009325331, 'depth': 5}. Best is trial 42 with value: 0.955885524229918.\n",
      "[I 2025-07-30 17:40:43,482] Trial 43 finished with value: 0.9514793937230743 and parameters: {'iterations': 954, 'learning_rate': 0.09497222617867558, 'depth': 5}. Best is trial 42 with value: 0.955885524229918.\n",
      "[I 2025-07-30 17:40:44,498] Trial 44 finished with value: 0.9430227485797992 and parameters: {'iterations': 864, 'learning_rate': 0.06454002006514108, 'depth': 5}. Best is trial 42 with value: 0.955885524229918.\n",
      "[I 2025-07-30 17:40:45,582] Trial 45 finished with value: 0.9554006851974337 and parameters: {'iterations': 958, 'learning_rate': 0.14208408337728112, 'depth': 5}. Best is trial 42 with value: 0.955885524229918.\n",
      "[I 2025-07-30 17:40:46,467] Trial 46 finished with value: 0.9532422058631608 and parameters: {'iterations': 788, 'learning_rate': 0.14352422952987473, 'depth': 5}. Best is trial 42 with value: 0.955885524229918.\n",
      "[I 2025-07-30 17:40:47,275] Trial 47 finished with value: 0.9471230796122814 and parameters: {'iterations': 898, 'learning_rate': 0.17191793628928628, 'depth': 4}. Best is trial 42 with value: 0.955885524229918.\n",
      "[I 2025-07-30 17:40:47,982] Trial 48 finished with value: 0.9436317078191506 and parameters: {'iterations': 955, 'learning_rate': 0.15958346785509359, 'depth': 3}. Best is trial 42 with value: 0.955885524229918.\n",
      "[I 2025-07-30 17:40:49,250] Trial 49 finished with value: 0.9525712047476123 and parameters: {'iterations': 847, 'learning_rate': 0.18881718960373325, 'depth': 6}. Best is trial 42 with value: 0.955885524229918.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 지정 피처: ['cement', 'blast furnace slag', 'fly ash', 'superplasticizer', 'coarse aggregate', 'age']\n",
      "📈 테스트 세트 기준 R²: 0.9559\n",
      "⚙️ 최적 하이퍼파라미터: {'iterations': 931, 'learning_rate': 0.1252659009325331, 'depth': 5}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "X = df[['cement', 'blast furnace slag', 'fly ash', 'superplasticizer', 'coarse aggregate', 'age']]\n",
    "y = df['CCS']\n",
    "\n",
    "# 학습/테스트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial, X_train, y_train, X_test, y_test):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "def optuna_tune_catboost(X_train, y_train, X_test, y_test, features, n_trials=50):\n",
    "    def tuned_objective(trial):\n",
    "        return objective(trial, X_train[features], y_train, X_test[features], y_test)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(tuned_objective, n_trials=n_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_model = CatBoostRegressor(**best_params, random_seed=42, verbose=0)\n",
    "    best_model.fit(X_train[features], y_train)\n",
    "    y_pred = best_model.predict(X_test[features])\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return r2, best_params\n",
    "\n",
    "# 지정 피처\n",
    "selected_features = ['cement', 'blast furnace slag', 'fly ash', 'superplasticizer', 'coarse aggregate', 'age']\n",
    "\n",
    "# 실행\n",
    "r2, best_params = optuna_tune_catboost(X_train, y_train, X_test, y_test, selected_features, n_trials=50)\n",
    "\n",
    "print(f\"📌 지정 피처: {selected_features}\")\n",
    "print(f\"📈 테스트 세트 기준 R²: {r2:.4f}\")\n",
    "print(f\"⚙️ 최적 하이퍼파라미터: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe649430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 교차검증 R² 점수들: [0.94912553 0.89685658 0.89493999 0.9114179  0.93547398]\n",
      "▶️ 평균 R²: 0.9176\n",
      "▶️ 표준편차 (std): 0.0214\n",
      "▶️ 분산 (var): 0.0005\n",
      "\n",
      "🧪 테스트 세트 R²: 0.9559\n"
     ]
    }
   ],
   "source": [
    "# 1) 최적 파라미터로 모델 생성\n",
    "model = CatBoostRegressor(**best_params, random_seed=42, verbose=0)\n",
    "\n",
    "# 2) 5‑폴드 교차검증용 설정\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 3) 교차검증으로 R² 점수 계산\n",
    "cv_scores = cross_val_score(\n",
    "    model,\n",
    "    X_train[selected_features],\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "# 4) 교차검증 결과 출력\n",
    "print(\"📊 교차검증 R² 점수들:\", cv_scores)\n",
    "print(f\"▶️ 평균 R²: {cv_scores.mean():.4f}\")\n",
    "print(f\"▶️ 표준편차 (std): {cv_scores.std():.4f}\")\n",
    "print(f\"▶️ 분산 (var): {cv_scores.var():.4f}\")\n",
    "\n",
    "# 5) 전체 학습 데이터로 모델 재학습 후, 테스트 세트 평가\n",
    "model.fit(X_train[selected_features], y_train)\n",
    "y_test_pred = model.predict(X_test[selected_features])\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"\\n🧪 테스트 세트 R²: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af11f835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
